{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV, GroupKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, ConstantKernel as RationalQuadratic\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from scipy.stats import sem, t\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD ALL DATAFRAMES (JUST MMSE USED HERE FOR EXAMPLE) ###\n",
    "\n",
    "mmse = pd.read_csv()\n",
    "\n",
    "mmse_standard = mmse.copy() # Used below for baseline model evaluation\n",
    "\n",
    "mmse['MMSE_ROC_12'] = mmse['MMSE_ROC_12'] + mmse['Baseline MMSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a415c08",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba710c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE A FUNCTION TO MAINTAIN SEX DISTRIBUTION ACROSS TRAIN TEST SPLITS ###\n",
    "\n",
    "def StratifiedGroupShuffleSplit(X, y, groups, n_splits, test_size=0.2, random_state=42):\n",
    "    # Split data by sex\n",
    "    f_idx = X[X['Sex'] == 2].index\n",
    "    X_f, y_f, groups_f = X.loc[f_idx], y.loc[f_idx], groups.loc[f_idx]\n",
    "\n",
    "    m_idx = X[X['Sex'] == 1].index\n",
    "    X_m, y_m, groups_m = X.loc[m_idx], y.loc[m_idx], groups.loc[m_idx]\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    gss_f = GroupShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    gss_m = GroupShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    for (train_idx_f, test_idx_f), (train_idx_m, test_idx_m) in zip(gss_f.split(X_f, y_f, groups_f), gss_m.split(X_m, y_m, groups_m)):\n",
    "        X_train_f, X_test_f = X_f.iloc[train_idx_f], X_f.iloc[test_idx_f]\n",
    "        y_train_f, y_test_f = y_f.iloc[train_idx_f], y_f.iloc[test_idx_f]\n",
    "        groups_train_f = groups_f.iloc[train_idx_f]\n",
    "\n",
    "        X_train_m, X_test_m = X_m.iloc[train_idx_m], X_m.iloc[test_idx_m]\n",
    "        y_train_m, y_test_m = y_m.iloc[train_idx_m], y_m.iloc[test_idx_m]\n",
    "        groups_train_m = groups_m.iloc[train_idx_m]\n",
    "\n",
    "        X_train = pd.concat([X_train_f, X_train_m])\n",
    "        y_train = pd.concat([y_train_f, y_train_m])\n",
    "        groups_train = pd.concat([groups_train_f, groups_train_m])\n",
    "\n",
    "        X_test = pd.concat([X_test_f, X_test_m])\n",
    "        y_test = pd.concat([y_test_f, y_test_m])\n",
    "\n",
    "        splits.append((X_train, y_train, groups_train, X_test, y_test))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION TO EVALUATE MODEL PERFORMANCE ###\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, groups_train, models=None, search_spaces=None):\n",
    "    if models is None:\n",
    "        models = {\n",
    "            \"Ridge\": Ridge(max_iter=10000),\n",
    "            \"Lasso\": Lasso(max_iter=10000),\n",
    "            \"ElasticNet\": ElasticNet(max_iter=10000),\n",
    "            \"XGBoost\": XGBRegressor(),\n",
    "            \"RandomForest\": RandomForestRegressor(random_state=42)\n",
    "        }\n",
    "    \n",
    "    if search_spaces is None:\n",
    "        search_spaces = {\n",
    "            \"Ridge\": {\n",
    "                \"model__alpha\": (1e-3, 1e4, \"log-uniform\")\n",
    "            },\n",
    "            \"Lasso\": {\n",
    "                \"model__alpha\": (1e-3, 10.0, \"log-uniform\"),\n",
    "                \"model__max_iter\": (1000, 10000)\n",
    "            },\n",
    "            \"ElasticNet\": {\n",
    "                \"model__alpha\": (1e-3, 10.0, \"log-uniform\"),\n",
    "                \"model__l1_ratio\": (0.1, 0.9, \"uniform\")\n",
    "            },\n",
    "            \"XGBoost\": {\n",
    "                \"model__n_estimators\": (50, 200),\n",
    "                \"model__max_depth\": (2, 6),\n",
    "                \"model__learning_rate\": (0.01, 0.1, \"log-uniform\"),\n",
    "                \"model__min_child_weight\": (5, 15),  \n",
    "                \"model__subsample\": (0.6, 1.0, \"uniform\"), \n",
    "                \"model__colsample_bytree\": (0.6, 1.0, \"uniform\"),  \n",
    "                \"model__gamma\": (0.1, 5, \"log-uniform\"),  \n",
    "                \"model__reg_alpha\": (0.1, 5.0, \"log-uniform\"),  \n",
    "                \"model__reg_lambda\": (1.0, 10.0, \"log-uniform\") \n",
    "            },\n",
    "            \"RandomForest\": {\n",
    "                \"model__n_estimators\": (50, 1000),\n",
    "                \"model__max_depth\": (3, 20),\n",
    "            }\n",
    "        }\n",
    "\n",
    "    results = {name: {\"MSE\": [], \"MAE\": [], \"R2\": []} for name in models} \n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('rfe', RFE(model)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            bayes_search = BayesSearchCV(\n",
    "                estimator=pipeline,\n",
    "                search_spaces=search_spaces[name],\n",
    "                cv=gkf, \n",
    "                n_iter=25,\n",
    "                scoring=\"neg_mean_squared_error\",  \n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            bayes_search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        best_model = bayes_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "        results[name][\"MSE\"].append(mse)\n",
    "        results[name][\"MAE\"].append(mae)\n",
    "        results[name][\"R2\"].append(r2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea52786",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NESTED CROSS VALIDATION: IMPLEMENTS train_and_evaluate() OVER TEN SPLITS ###\n",
    "\n",
    "def nested_cv(X, y, groups):\n",
    "    all_results = []\n",
    "    summary_rows = []\n",
    "\n",
    "    splits = StratifiedGroupShuffleSplit(X, y, groups, n_splits=10)\n",
    "\n",
    "    for X_train, y_train, groups_train, X_test, y_test in tqdm(splits, total=10, desc=\"Outer CV (Splits)\"):\n",
    "        split_results = train_and_evaluate(X_train, y_train, X_test, y_test, groups_train)\n",
    "        all_results.append(split_results)\n",
    "\n",
    "    for name in all_results[0].keys():\n",
    "        mse_values = []\n",
    "        mae_values = []\n",
    "        r2_values = []\n",
    "\n",
    "        for split in all_results:\n",
    "            mse_values.extend(split[name][\"MSE\"])\n",
    "            mae_values.extend(split[name][\"MAE\"])\n",
    "            r2_values.extend(split[name][\"R2\"])\n",
    "\n",
    "        avg_mse = sum(mse_values) / len(mse_values)\n",
    "        avg_mae = sum(mae_values) / len(mae_values)\n",
    "        avg_r2 = sum(r2_values) / len(r2_values)\n",
    "\n",
    "        mse_sem = sem(mse_values)\n",
    "        mae_sem = sem(mae_values)\n",
    "        r2_sem = sem(r2_values)\n",
    "\n",
    "        mse_ci = 1.96 * mse_sem\n",
    "        mae_ci = 1.96 * mae_sem\n",
    "        r2_ci = 1.96 * r2_sem\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Model\": name,\n",
    "            \"MSE (95% CI)\": f\"{avg_mse:.1f} ({avg_mse - mse_ci:.1f} – {avg_mse + mse_ci:.1f})\",\n",
    "            \"MAE (95% CI)\": f\"{avg_mae:.1f} ({avg_mae - mae_ci:.1f} – {avg_mae + mae_ci:.1f})\",\n",
    "            \"R^2 (95% CI)\": f\"{avg_r2:.1f} ({avg_r2 - r2_ci:.1f} – {avg_r2 + r2_ci:.1f})\",\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows).set_index(\"Model\")\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    # print(summary_df)\n",
    "    print(summary_df.to_latex())\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06111ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR MLP and GP ###\n",
    "\n",
    "def train_and_evaluate_mlpgp(X_train, y_train, X_test, y_test, groups_train, models=None, search_spaces=None):\n",
    "    input_neurons = X_train.shape[1]\n",
    "    HL_1 = input_neurons\n",
    "    HL_2 = int(HL_1 * 0.75)\n",
    "    HL_3 = int(HL_2 * 0.75)\n",
    "    \n",
    "    if models is None:\n",
    "        models = {\n",
    "            \"MLP\": MLPRegressor(max_iter=1000, hidden_layer_sizes=(HL_1, HL_2, HL_3), random_state=42),\n",
    "            \"GP\": GaussianProcessRegressor(random_state=42),\n",
    "        }\n",
    "    \n",
    "    if search_spaces is None:\n",
    "        search_spaces = {\n",
    "            \"MLP\": {\n",
    "                \"model__activation\": ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                \"model__solver\": ['lbfgs', 'sgd', 'adam']\n",
    "            },\n",
    "            \"GP\": {\n",
    "                \"model__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "                \"model__kernel\": (\n",
    "                    [RBF(length_scale) for length_scale in np.logspace(-3, 1, 5)] +\n",
    "                    [DotProduct(sigma_0) for sigma_0 in np.logspace(-3, 1, 5)] +\n",
    "                    [RationalQuadratic(length_scale=l, alpha=a)\n",
    "                    for l in np.logspace(-3, 1, 3)\n",
    "                    for a in np.logspace(-3, 1, 3)]\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "\n",
    "    results = {name: {\"MSE\": [], \"MAE\": [], \"R2\": []} for name in models} \n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # print(f\"Optimizing {name}...\")\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=search_spaces[name],\n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            cv=gkf,\n",
    "        )\n",
    "\n",
    "        search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "        results[name][\"MSE\"].append(mse)\n",
    "        results[name][\"MAE\"].append(mae)\n",
    "        results[name][\"R2\"].append(r2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_mlpgp(X, y, groups):   \n",
    "    all_results = []\n",
    "    summary_rows = []\n",
    "\n",
    "    splits = StratifiedGroupShuffleSplit(X, y, groups, n_splits=10)\n",
    "\n",
    "    for X_train, y_train, groups_train, X_test, y_test in tqdm(splits, total=10, desc=\"Outer CV (Splits)\"):\n",
    "        split_results = train_and_evaluate_mlpgp(X_train, y_train, X_test, y_test, groups_train)\n",
    "        all_results.append(split_results)\n",
    "\n",
    "    for name in all_results[0].keys():  # Loop over model names\n",
    "        mse_values = []\n",
    "        mae_values = []\n",
    "        r2_values = []\n",
    "\n",
    "        for split in all_results:\n",
    "            mse_values.extend(split[name][\"MSE\"])\n",
    "            mae_values.extend(split[name][\"MAE\"])\n",
    "            r2_values.extend(split[name][\"R2\"])\n",
    "\n",
    "        avg_mse = sum(mse_values) / len(mse_values)\n",
    "        avg_mae = sum(mae_values) / len(mae_values)\n",
    "        avg_r2 = sum(r2_values) / len(r2_values)\n",
    "\n",
    "        mse_sem = sem(mse_values)\n",
    "        mae_sem = sem(mae_values)\n",
    "        r2_sem = sem(r2_values)\n",
    "\n",
    "        mse_ci = 1.96 * mse_sem\n",
    "        mae_ci = 1.96 * mae_sem\n",
    "        r2_ci = 1.96 * r2_sem\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Model\": name,\n",
    "            \"MSE (95% CI)\": f\"{avg_mse:.1f} ({avg_mse - mse_ci:.1f} – {avg_mse + mse_ci:.1f})\",\n",
    "            \"MAE (95% CI)\": f\"{avg_mae:.1f} ({avg_mae - mae_ci:.1f} – {avg_mae + mae_ci:.1f})\",\n",
    "            \"R^2 (95% CI)\": f\"{avg_r2:.1f} ({avg_r2 - r2_ci:.1f} – {avg_r2 + r2_ci:.1f})\",\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows).set_index(\"Model\")\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(summary_df.to_latex())\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e10652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mmse = mmse.drop(columns=['MMSE_ROC_12', 'Dyad'])\n",
    "y_mmse = mmse['MMSE_ROC_12']\n",
    "groups_mmse = mmse['Dyad']\n",
    "\n",
    "# Repeat for all other feature combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2d301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cv(X_mmse, y_mmse, groups_mmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8074474",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_cv_mlpgp(X_mmse, y_mmse, groups_mmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e658bd15",
   "metadata": {},
   "source": [
    "# Baseline Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mmse_roc = mmse_standard['MMSE_ROC_12'].mean()\n",
    "mmse_standard['MMSE_ROC_12'] = mmse_standard['Baseline MMSE'] + mean_mmse_roc\n",
    "\n",
    "X_mmse_standard = mmse_standard.drop(columns=['MMSE_ROC_12', 'Dyad'])\n",
    "y_mmse_standard = mmse_standard['MMSE_ROC_12']\n",
    "groups_mmse_standard = mmse_standard['Dyad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e47f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = StratifiedGroupShuffleSplit(X_mmse_standard, y_mmse_standard, groups_mmse_standard, n_splits=10)\n",
    "naive_model = DummyRegressor(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for X_train, y_train, groups_train, X_test, y_test in tqdm(splits, total=10, desc=\"Outer CV (Splits)\"):\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "    naive_model.fit(X_train, y_train)\n",
    "    y_pred = naive_model.predict(X_test)\n",
    "\n",
    "    mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "\n",
    "mse_scores = np.array(mse_scores)\n",
    "mae_scores = np.array(mae_scores)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "avg_mse = sum(mse_scores) / len(mse_scores)\n",
    "avg_mae = sum(mae_scores) / len(mae_scores)\n",
    "avg_r2 = sum(r2_scores) / len(r2_scores)\n",
    "\n",
    "mse_sem = sem(mse_scores)\n",
    "mae_sem = sem(mae_scores)\n",
    "r2_sem = sem(r2_scores)\n",
    "\n",
    "mse_ci = 1.96 * mse_sem\n",
    "mae_ci = 1.96 * mae_sem\n",
    "r2_ci = 1.96 * r2_sem\n",
    "\n",
    "print(\"MSE (95% CI):\", f\"{avg_mse:.1f} ({avg_mse - mse_ci:.1f} – {avg_mse + mse_ci:.1f})\")\n",
    "print(\"MAE (95% CI):\", f\"{avg_mae:.1f} ({avg_mae - mae_ci:.1f} – {avg_mae + mae_ci:.1f})\")\n",
    "print(\"R^2 (95% CI):\", f\"{avg_r2:.1f} ({avg_r2 - r2_ci:.1f} – {avg_r2 + r2_ci:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad3650",
   "metadata": {},
   "source": [
    "# Final model training - on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_training(X, y, groups, models=None, search_spaces=None, models_to_run=None):\n",
    "    \n",
    "    if models is None:\n",
    "        models = {\n",
    "            \"Ridge\": Ridge(),\n",
    "            \"Lasso\": Lasso(),\n",
    "            \"ElasticNet\": ElasticNet(),\n",
    "            \"XGBoost\": XGBRegressor(),\n",
    "            \"Random Forest\": RandomForestRegressor(random_state=42)\n",
    "        }\n",
    "    \n",
    "    if search_spaces is None:\n",
    "        search_spaces = {\n",
    "            \"Ridge\": {\n",
    "                \"model__alpha\": (1e-2, 1e4, \"log-uniform\")\n",
    "            },\n",
    "            \"Lasso\": {\n",
    "                \"model__alpha\": (1e-2, 10.0, \"log-uniform\"),\n",
    "                \"model__max_iter\": (1000, 5000, 10000)\n",
    "            },\n",
    "            \"ElasticNet\": {\n",
    "                \"model__alpha\": (1e-2, 10.0, \"log-uniform\"),\n",
    "                \"model__l1_ratio\": (0.1, 0.6, \"uniform\")\n",
    "            },\n",
    "            \"XGBoost\": {\n",
    "                \"model__n_estimators\": (50, 200),\n",
    "                \"model__max_depth\": (2, 6),\n",
    "                \"model__learning_rate\": (0.01, 0.1, \"log-uniform\"),\n",
    "                \"model__min_child_weight\": (5, 15),  # Less aggressive fitting\n",
    "                \"model__subsample\": (0.6, 1.0, \"uniform\"),  # Control overfitting\n",
    "                \"model__colsample_bytree\": (0.6, 1.0, \"uniform\"),  # Feature selection\n",
    "                \"model__gamma\": (0.1, 5, \"log-uniform\"),  # Prevent unnecessary splits\n",
    "                \"model__reg_alpha\": (0.1, 5.0, \"log-uniform\"),  # L1 regularization\n",
    "                \"model__reg_lambda\": (1.0, 10.0, \"log-uniform\")  # L2 regularization\n",
    "            },\n",
    "            \"Random Forest\": {\n",
    "                \"model__n_estimators\": (50, 500),\n",
    "                \"model__max_depth\": (3, 10),\n",
    "            },\n",
    "        }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=10)\n",
    "\n",
    "    if models_to_run is not None:\n",
    "        models = {name: model for name, model in models.items() if name in models_to_run}\n",
    "        search_spaces = {name: space for name, space in search_spaces.items() if name in models_to_run}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('rfe', RFE(estimator=model)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Initialize BayesSearchCV\n",
    "        bayes_search = BayesSearchCV(\n",
    "            estimator=pipeline,\n",
    "            search_spaces=search_spaces[name],\n",
    "            cv=gkf, \n",
    "            n_iter=50,  # Number of parameter combinations to try\n",
    "            scoring=\"neg_mean_squared_error\",  # Optimize for MSE\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit BayesSearchCV on the training data\n",
    "        bayes_search.fit(X, y, groups=groups)\n",
    "\n",
    "        print(f\"Best parameters for {name}: {bayes_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff356b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training(X_mmse, y_mmse, groups_mmse, models_to_run=['ElasticNet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8ff1a",
   "metadata": {},
   "source": [
    "# SHAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be42f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rfe', RFE(model)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X, y)\n",
    "\n",
    "    selected_features_mask = pipeline.named_steps['rfe'].support_\n",
    "    selected_features = X.columns[selected_features_mask]\n",
    "    X_selected = X[selected_features]\n",
    "\n",
    "    model = pipeline.named_steps['model']\n",
    "\n",
    "    scaler = pipeline.named_steps['scaler']\n",
    "    X_selected = pd.DataFrame(scaler.fit_transform(X_selected), columns=X_selected.columns)\n",
    "    \n",
    "    explainer = shap.Explainer(model, X_selected)\n",
    "    shap_values = explainer.shap_values(X_selected)\n",
    "\n",
    "    return shap_values, X_selected\n",
    "\n",
    "def shap_plot(shap_values, X_selected):\n",
    "\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        shap_values, X_selected, max_display=10, plot_size=(12,5), show=False, plot_type='violin' #, cmap='crest'\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.gcf(), plt.gca()\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    for text in ax.texts:\n",
    "        text.set_color('black')\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_color('black')\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_color('black')\n",
    "\n",
    "    ax.xaxis.label.set_color('black')\n",
    "    ax.yaxis.label.set_color('black')\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.set_xlabel(\"SHAP value\", fontsize=14, color='black')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('black')\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.spines['bottom'].set_color('black')\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "\n",
    "    for line in ax.lines:\n",
    "        line.set_linewidth(2) \n",
    "\n",
    "    ax.set_aspect('auto', adjustable='box')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(alpha=, l1_ratio=)\n",
    "shap_values, X_selected=train_model(model, X_mmse, y_mmse)\n",
    "shap_plot(shap_values, X_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
